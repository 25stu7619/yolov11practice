# YOLOv11 ì™„ì „ ê°€ì´ë“œ (Complete Guide)

<div align="center">

![YOLOv11](https://img.shields.io/badge/YOLOv11-2024-blue)
![Python](https://img.shields.io/badge/Python-3.8+-green)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange)
![License](https://img.shields.io/badge/License-AGPL--3.0-red)

**ìµœì‹  YOLO ì‹œë¦¬ì¦ˆì˜ ì°¨ì„¸ëŒ€ ê°ì²´ íƒì§€ ëª¨ë¸**

</div>

---

## ğŸ“‘ ëª©ì°¨

1. [YOLOv11 ì†Œê°œ](#-yolov11-ì†Œê°œ)
2. [ì£¼ìš” íŠ¹ì§•](#-ì£¼ìš”-íŠ¹ì§•)
3. [ì„¤ì¹˜ ë°©ë²•](#-ì„¤ì¹˜-ë°©ë²•)
4. [ë¹ ë¥¸ ì‹œì‘](#-ë¹ ë¥¸-ì‹œì‘)
5. [ëª¨ë¸ êµ¬ì¡°](#-ëª¨ë¸-êµ¬ì¡°)
6. [ì‚¬ìš© ì˜ˆì œ](#-ì‚¬ìš©-ì˜ˆì œ)
7. [í•™ìŠµ (Training)](#-í•™ìŠµ-training)
8. [ì¶”ë¡  (Inference)](#-ì¶”ë¡ -inference)
9. [ëª¨ë¸ ë‚´ë³´ë‚´ê¸°](#-ëª¨ë¸-ë‚´ë³´ë‚´ê¸°)
10. [ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬](#-ì„±ëŠ¥-ë²¤ì¹˜ë§ˆí¬)
11. [í•˜ì´í¼íŒŒë¼ë¯¸í„°](#-í•˜ì´í¼íŒŒë¼ë¯¸í„°)
12. [Tips & Tricks](#-tips--tricks)
13. [FAQ](#-faq)
14. [ì°¸ê³  ìë£Œ](#-ì°¸ê³ -ìë£Œ)

---

## ğŸš€ YOLOv11 ì†Œê°œ

**YOLOv11**ì€ Ultralyticsì—ì„œ 2024ë…„ 9ì›”ì— ì¶œì‹œí•œ ìµœì‹  ê°ì²´ íƒì§€ ëª¨ë¸ì…ë‹ˆë‹¤. YOLOv8 ëŒ€ë¹„ **ë” ì ì€ íŒŒë¼ë¯¸í„°**ë¡œ **ë” ë†’ì€ ì •í™•ë„**ì™€ **ë” ë¹ ë¥¸ ì†ë„**ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

### ì£¼ìš” ê°œì„ ì‚¬í•­
- ğŸ¯ **ì •í™•ë„ í–¥ìƒ**: mAP 2~3% ìƒìŠ¹
- âš¡ **ì†ë„ ê°œì„ **: ì•½ 22% ì¶”ë¡  ì†ë„ í–¥ìƒ
- ğŸ’¾ **ê²½ëŸ‰í™”**: íŒŒë¼ë¯¸í„° ìˆ˜ 19~22% ê°ì†Œ
- ğŸ—ï¸ **ì•„í‚¤í…ì²˜**: C3k2, C2PSA ëª¨ë“ˆ ë„ì…
- ğŸ”§ **ì•ˆì •ì„±**: ë”ìš± ì•ˆì •ì ì¸ í•™ìŠµ í”„ë¡œì„¸ìŠ¤

---

## âœ¨ ì£¼ìš” íŠ¹ì§•

### 1. ë‹¤ì–‘í•œ íƒœìŠ¤í¬ ì§€ì›
- **Object Detection**: ê°ì²´ íƒì§€
- **Instance Segmentation**: ì¸ìŠ¤í„´ìŠ¤ ë¶„í• 
- **Pose Estimation**: í¬ì¦ˆ ì¶”ì •
- **Oriented Object Detection (OBB)**: íšŒì „ ë°•ìŠ¤ íƒì§€
- **Image Classification**: ì´ë¯¸ì§€ ë¶„ë¥˜

### 2. 5ê°€ì§€ ëª¨ë¸ í¬ê¸°
| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | mAP50-95 | ì†ë„ (T4) | ìš©ë„ |
|------|----------|----------|-----------|------|
| YOLOv11n | 2.6M | 39.5% | 1.0ms | ì—£ì§€ ë””ë°”ì´ìŠ¤ |
| YOLOv11s | 9.4M | 47.0% | 1.7ms | ëª¨ë°”ì¼ |
| YOLOv11m | 20.1M | 51.5% | 2.9ms | ì¼ë°˜ ìš©ë„ |
| YOLOv11l | 25.3M | 53.4% | 4.1ms | ê³ ì„±ëŠ¥ |
| YOLOv11x | 56.9M | 54.7% | 6.5ms | ìµœê³  ì„±ëŠ¥ |

### 3. í”„ë ˆì„ì›Œí¬ ì§€ì›
- âœ… PyTorch
- âœ… ONNX
- âœ… TensorRT
- âœ… CoreML
- âœ… OpenVINO
- âœ… TensorFlow Lite

---

## ğŸ“¦ ì„¤ì¹˜ ë°©ë²•

### pipë¥¼ í†µí•œ ì„¤ì¹˜ (ê¶Œì¥)

```bash
# ìµœì‹  ë²„ì „ ì„¤ì¹˜
pip install ultralytics

# íŠ¹ì • ë²„ì „ ì„¤ì¹˜
pip install ultralytics==8.3.0

# ê°œë°œ ë²„ì „ ì„¤ì¹˜ (ìµœì‹  ê¸°ëŠ¥)
pip install git+https://github.com/ultralytics/ultralytics.git
```

### condaë¥¼ í†µí•œ ì„¤ì¹˜

```bash
conda install -c conda-forge ultralytics
```

### ì†ŒìŠ¤ì—ì„œ ì„¤ì¹˜

```bash
git clone https://github.com/ultralytics/ultralytics.git
cd ultralytics
pip install -e .
```

### ì˜ì¡´ì„± í™•ì¸

```bash
pip install torch torchvision opencv-python numpy pillow pyyaml
```

**ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­:**
- Python 3.8+
- PyTorch 1.8+
- CUDA 11.0+ (GPU ì‚¬ìš© ì‹œ)

---

## ğŸƒ ë¹ ë¥¸ ì‹œì‘

### 1. CLI (Command Line Interface)

```bash
# ì´ë¯¸ì§€ ì˜ˆì¸¡
yolo detect predict model=yolov11n.pt source='image.jpg'

# ì›¹ìº  ì‹¤ì‹œê°„ íƒì§€
yolo detect predict model=yolov11n.pt source=0

# ë¹„ë””ì˜¤ ì˜ˆì¸¡
yolo detect predict model=yolov11n.pt source='video.mp4'

# í•™ìŠµ
yolo detect train data=coco.yaml model=yolov11n.pt epochs=100

# ê²€ì¦
yolo detect val model=yolov11n.pt data=coco.yaml

# ëª¨ë¸ ë‚´ë³´ë‚´ê¸°
yolo export model=yolov11n.pt format=onnx
```

### 2. Python API

```python
from ultralytics import YOLO

# ëª¨ë¸ ë¡œë“œ
model = YOLO('yolov11n.pt')

# ì´ë¯¸ì§€ ì˜ˆì¸¡
results = model('image.jpg')

# ê²°ê³¼ ì¶œë ¥
for result in results:
    boxes = result.boxes  # Boxes object
    print(boxes.xyxy)     # ë°•ìŠ¤ ì¢Œí‘œ
    print(boxes.conf)     # ì‹ ë¢°ë„
    print(boxes.cls)      # í´ë˜ìŠ¤ ID

# ê²°ê³¼ ì €ì¥
results[0].save('result.jpg')

# ê²°ê³¼ ì‹œê°í™”
results[0].show()
```

---

## ğŸ—ï¸ ëª¨ë¸ êµ¬ì¡°

### ì „ì²´ ì•„í‚¤í…ì²˜

```
Input Image (640x640)
    â†“
[Backbone - Feature Extraction]
    â†“ C3k2 Blocks
    â†“ Down-sampling
    â†“ SPPF
    â†“
[Neck - Feature Fusion]
    â†“ C2PSA (Attention)
    â†“ PAN Structure
    â†“ Multi-scale Features
    â†“
[Head - Detection]
    â†“ Decoupled Head
    â†“ Classification + Regression
    â†“
Output (Boxes, Classes, Scores)
```

### ì£¼ìš” ëª¨ë“ˆ

#### 1. C3k2 (CSP Bottleneck with 2 convolutions - k2)
```python
# C3k2 êµ¬ì¡° ê°œë…
class C3k2:
    def __init__(self, in_channels, out_channels):
        # Split channels
        # Bottleneck layers
        # Concat and Conv
        pass
```
**íŠ¹ì§•:**
- CSP êµ¬ì¡° ê¸°ë°˜
- íš¨ìœ¨ì ì¸ íŠ¹ì§• ì¶”ì¶œ
- íŒŒë¼ë¯¸í„° ê°ì†Œ

#### 2. C2PSA (C2 with Partial Self-Attention)
```python
# C2PSA êµ¬ì¡° ê°œë…
class C2PSA:
    def __init__(self, channels):
        # Partial Self-Attention
        # Channel split
        # Attention on subset
        pass
```
**íŠ¹ì§•:**
- ë¶€ë¶„ Self-Attention ì‚¬ìš©
- ê³„ì‚°ëŸ‰ ê°ì†Œ
- ì¥ê±°ë¦¬ ì˜ì¡´ì„± í¬ì°©

#### 3. SPPF (Spatial Pyramid Pooling - Fast)
- ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŠ¹ì§• ì¶”ì¶œ
- ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„
- ìˆ˜ìš© ì˜ì—­(Receptive Field) í™•ëŒ€

---

## ğŸ’» ì‚¬ìš© ì˜ˆì œ

### ê°ì²´ íƒì§€ (Object Detection)

```python
from ultralytics import YOLO
import cv2

# ëª¨ë¸ ë¡œë“œ
model = YOLO('yolov11n.pt')

# ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡
results = model('bus.jpg')

# ì—¬ëŸ¬ ì´ë¯¸ì§€ ì˜ˆì¸¡
results = model(['image1.jpg', 'image2.jpg', 'image3.jpg'])

# ë°°ì¹˜ ì˜ˆì¸¡ (ë” ë¹ ë¦„)
results = model(['image1.jpg', 'image2.jpg'], batch=2)

# ê²°ê³¼ ì²˜ë¦¬
for result in results:
    # ë°•ìŠ¤ ì •ë³´
    boxes = result.boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2]
    confidences = result.boxes.conf.cpu().numpy()
    class_ids = result.boxes.cls.cpu().numpy()
    
    # ì´ë¯¸ì§€ì— ê·¸ë¦¬ê¸°
    img = result.orig_img
    for box, conf, cls in zip(boxes, confidences, class_ids):
        x1, y1, x2, y2 = map(int, box)
        label = f'{model.names[int(cls)]} {conf:.2f}'
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(img, label, (x1, y1-10), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    
    cv2.imwrite('output.jpg', img)
```

### ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬

```python
from ultralytics import YOLO
import cv2

model = YOLO('yolov11n.pt')

# ì›¹ìº  ì—´ê¸°
cap = cv2.VideoCapture(0)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    # ì˜ˆì¸¡ (stream=Trueë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ)
    results = model(frame, stream=True)
    
    # ê²°ê³¼ ì‹œê°í™”
    for result in results:
        annotated_frame = result.plot()
        cv2.imshow('YOLOv11', annotated_frame)
    
    # 'q' í‚¤ë¡œ ì¢…ë£Œ
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

### íŠ¹ì • í´ë˜ìŠ¤ë§Œ íƒì§€

```python
from ultralytics import YOLO

model = YOLO('yolov11n.pt')

# ì‚¬ëŒ(class 0)ê³¼ ìë™ì°¨(class 2)ë§Œ íƒì§€
results = model('street.jpg', classes=[0, 2])

# ë˜ëŠ” íŠ¹ì • í´ë˜ìŠ¤ ì œì™¸
results = model('street.jpg', classes=[0, 1, 2, 3])  # 0~3ë²ˆ í´ë˜ìŠ¤ë§Œ
```

### ì‹ ë¢°ë„ ì„ê³„ê°’ ì„¤ì •

```python
from ultralytics import YOLO

model = YOLO('yolov11n.pt')

# ì‹ ë¢°ë„ 0.5 ì´ìƒë§Œ í‘œì‹œ
results = model('image.jpg', conf=0.5)

# IoU ì„ê³„ê°’ ì¡°ì • (NMS)
results = model('image.jpg', iou=0.7)

# ë™ì‹œ ì„¤ì •
results = model('image.jpg', conf=0.4, iou=0.6)
```

### ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •

```python
from ultralytics import YOLO

model = YOLO('yolov11n.pt')

# ê¸°ë³¸ í¬ê¸° (640)
results = model('image.jpg')

# ì‚¬ìš©ì ì •ì˜ í¬ê¸° (ë” í° ì´ë¯¸ì§€ = ë” ë†’ì€ ì •í™•ë„, ëŠë¦° ì†ë„)
results = model('image.jpg', imgsz=1280)

# ì‘ì€ ì´ë¯¸ì§€ë¡œ ë¹ ë¥¸ ì²˜ë¦¬
results = model('image.jpg', imgsz=320)
```

---

## ğŸ“ í•™ìŠµ (Training)

### ê¸°ë³¸ í•™ìŠµ

```python
from ultralytics import YOLO

# ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì—ì„œ ì‹œì‘ (ì „ì´ í•™ìŠµ)
model = YOLO('yolov11n.pt')

# í•™ìŠµ ì‹œì‘
results = model.train(
    data='coco.yaml',      # ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼
    epochs=100,            # ì—í¬í¬ ìˆ˜
    imgsz=640,             # ì´ë¯¸ì§€ í¬ê¸°
    batch=16,              # ë°°ì¹˜ í¬ê¸°
    name='yolov11_custom', # ì‹¤í—˜ ì´ë¦„
    device=0,              # GPU ë²ˆí˜¸ (0, 1, 2, ... ë˜ëŠ” 'cpu')
)
```

### CLIë¡œ í•™ìŠµ

```bash
yolo detect train \
    data=coco.yaml \
    model=yolov11n.pt \
    epochs=100 \
    imgsz=640 \
    batch=16 \
    device=0 \
    project=runs/train \
    name=exp
```

### ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ì¤€ë¹„

#### 1. ë°ì´í„°ì…‹ êµ¬ì¡°

```
dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”‚   â””â”€â”€ image2.jpg
â”‚   â””â”€â”€ val/
â”‚       â”œâ”€â”€ image3.jpg
â”‚       â””â”€â”€ image4.jpg
â””â”€â”€ labels/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ image1.txt
    â”‚   â””â”€â”€ image2.txt
    â””â”€â”€ val/
        â”œâ”€â”€ image3.txt
        â””â”€â”€ image4.txt
```

#### 2. ë¼ë²¨ í˜•ì‹ (YOLO Format)

```txt
# image1.txt
# class_id x_center y_center width height (ì •ê·œí™”ëœ ê°’ 0~1)
0 0.5 0.5 0.3 0.4
1 0.3 0.7 0.2 0.15
```

#### 3. ë°ì´í„°ì…‹ YAML íŒŒì¼

```yaml
# dataset.yaml
path: /path/to/dataset  # ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ
train: images/train     # í•™ìŠµ ì´ë¯¸ì§€ ê²½ë¡œ
val: images/val         # ê²€ì¦ ì´ë¯¸ì§€ ê²½ë¡œ
test: images/test       # (ì„ íƒ) í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ

# í´ë˜ìŠ¤ ì •ì˜
names:
  0: person
  1: bicycle
  2: car
  3: motorcycle
  # ...

# í´ë˜ìŠ¤ ìˆ˜
nc: 80
```

### ê³ ê¸‰ í•™ìŠµ ì˜µì…˜

```python
from ultralytics import YOLO

model = YOLO('yolov11n.pt')

results = model.train(
    # í•„ìˆ˜ íŒŒë¼ë¯¸í„°
    data='custom.yaml',
    epochs=100,
    
    # ì´ë¯¸ì§€ ë° ë°°ì¹˜
    imgsz=640,
    batch=16,
    
    # í•™ìŠµë¥ 
    lr0=0.01,              # ì´ˆê¸° í•™ìŠµë¥ 
    lrf=0.01,              # ìµœì¢… í•™ìŠµë¥  (lr0 * lrf)
    
    # ì˜µí‹°ë§ˆì´ì €
    optimizer='SGD',       # SGD, Adam, AdamW
    momentum=0.937,
    weight_decay=0.0005,
    
    # ë°ì´í„° ì¦ê°•
    hsv_h=0.015,          # HSV-Hue ì¦ê°•
    hsv_s=0.7,            # HSV-Saturation ì¦ê°•
    hsv_v=0.4,            # HSV-Value ì¦ê°•
    degrees=0.0,          # ì´ë¯¸ì§€ íšŒì „ (Â±ë„)
    translate=0.1,        # ì´ë¯¸ì§€ ì´ë™ (Â±ë¶„ìœ¨)
    scale=0.5,            # ì´ë¯¸ì§€ ìŠ¤ì¼€ì¼ (Â±ì¦ê°)
    shear=0.0,            # ì´ë¯¸ì§€ ì „ë‹¨ (Â±ë„)
    perspective=0.0,      # ì´ë¯¸ì§€ ì›ê·¼ (Â±ë¶„ìœ¨)
    flipud=0.0,           # ìƒí•˜ ë’¤ì§‘ê¸° (í™•ë¥ )
    fliplr=0.5,           # ì¢Œìš° ë’¤ì§‘ê¸° (í™•ë¥ )
    mosaic=1.0,           # Mosaic ì¦ê°• (í™•ë¥ )
    mixup=0.0,            # MixUp ì¦ê°• (í™•ë¥ )
    
    # ì •ê·œí™”
    dropout=0.0,          # Dropout ë¹„ìœ¨
    
    # ê¸°íƒ€
    patience=50,          # ì¡°ê¸° ì¢…ë£Œ patience
    save=True,            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    save_period=10,       # ë§¤ N ì—í¬í¬ë§ˆë‹¤ ì €ì¥
    workers=8,            # ë°ì´í„° ë¡œë” ì›Œì»¤ ìˆ˜
    device=0,             # GPU ë””ë°”ì´ìŠ¤
    verbose=True,         # ìƒì„¸ ì¶œë ¥
    
    # ì¬ê°œ ë° ì „ì´ í•™ìŠµ
    resume=False,         # ì´ì „ í•™ìŠµ ì¬ê°œ
    amp=True,             # Automatic Mixed Precision
    
    # ê²€ì¦
    val=True,             # ë§¤ ì—í¬í¬ë§ˆë‹¤ ê²€ì¦
    
    # í”„ë¡œì íŠ¸ ê´€ë¦¬
    project='runs/train',
    name='exp',
    exist_ok=False,       # ê¸°ì¡´ í”„ë¡œì íŠ¸ ë®ì–´ì“°ê¸°
)
```

### ë‹¤ì¤‘ GPU í•™ìŠµ

```bash
# PyTorch DDP (ê¶Œì¥)
yolo detect train data=coco.yaml model=yolov11n.pt epochs=100 device=0,1,2,3
```

```python
# Pythonì—ì„œ
from ultralytics import YOLO

model = YOLO('yolov11n.pt')
model.train(data='coco.yaml', epochs=100, device=[0, 1, 2, 3])
```

### í•™ìŠµ ì¤‘ë‹¨ ë° ì¬ê°œ

```python
from ultralytics import YOLO

# í•™ìŠµ ì¬ê°œ (last.ptì—ì„œ)
model = YOLO('runs/train/exp/weights/last.pt')
model.train(resume=True)

# ë˜ëŠ” CLI
# yolo detect train resume model=runs/train/exp/weights/last.pt
```

---

## ğŸ” ì¶”ë¡  (Inference)

### ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ì¶”ë¡ 

```python
from ultralytics import YOLO

model = YOLO('yolov11n.pt')

# 1. ì´ë¯¸ì§€ íŒŒì¼
results = model('image.jpg')

# 2. ì´ë¯¸ì§€ URL
results = model('https://example.com/image.jpg')

# 3. NumPy ë°°ì—´ (OpenCV)
import cv2
img = cv2.imread('image.jpg')
results = model(img)

# 4. PIL Image
from PIL import Image
img = Image.open('image.jpg')
results = model(img)

# 5. ë¹„ë””ì˜¤ íŒŒì¼
results = model('video.mp4')

# 6. ì›¹ìº 
results = model(0)  # 0ì€ ê¸°ë³¸ ì›¹ìº 

# 7. RTSP/HTTP ìŠ¤íŠ¸ë¦¼
results = model('rtsp://192.168.1.100:554/stream')

# 8. ë””ë ‰í† ë¦¬ (ëª¨ë“  ì´ë¯¸ì§€)
results = model('path/to/images/')

# 9. ì™€ì¼ë“œì¹´ë“œ
results = model('path/to/*.jpg')
```

### ê²°ê³¼ ì²˜ë¦¬ ë° ë¶„ì„

```python
from ultralytics import YOLO

model = YOLO('yolov11n.pt')
results = model('image.jpg')

for result in results:
    # ì›ë³¸ ì´ë¯¸ì§€
    orig_img = result.orig_img
    
    # ë°•ìŠ¤ ì •ë³´
    boxes = result.boxes
    
    # ë°•ìŠ¤ ì¢Œí‘œ (ë‹¤ì–‘í•œ í˜•ì‹)
    xyxy = boxes.xyxy      # [x1, y1, x2, y2]
    xywh = boxes.xywh      # [x_center, y_center, width, height]
    xyxyn = boxes.xyxyn    # ì •ê·œí™”ëœ xyxy
    xywhn = boxes.xywhn    # ì •ê·œí™”ëœ xywh
    
    # ì‹ ë¢°ë„ ë° í´ë˜ìŠ¤
    conf = boxes.conf      # ì‹ ë¢°ë„ ì ìˆ˜
    cls = boxes.cls        # í´ë˜ìŠ¤ ID
    
    # í´ë˜ìŠ¤ ì´ë¦„
    names = result.names
    for c in cls:
        print(names[int(c)])
    
    # ê²°ê³¼ ì €ì¥
    result.save('output.jpg')
    
    # ê²°ê³¼ í‘œì‹œ
    result.show()
    
    # ì£¼ì„ì´ ë‹¬ë¦° ì´ë¯¸ì§€
    annotated = result.plot()
    
    # JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°
    json_results = result.tojson()
    
    # Pandas DataFrameìœ¼ë¡œ
    df = result.pandas().xyxy[0]
    print(df)
```

### ì¶”ë¡  ìµœì í™”

```python
from ultralytics import YOLO

model = YOLO('yolov11n.pt')

# Half precision (FP16) - GPUì—ì„œ ë” ë¹ ë¦„
model = YOLO('yolov11n.pt')
results = model('image.jpg', half=True)

# ìµœëŒ€ íƒì§€ ìˆ˜ ì œí•œ
results = model('image.jpg', max_det=100)

# ë” ì‘ì€ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë¹ ë¥¸ ì¶”ë¡ 
results = model('image.jpg', imgsz=320)

# NMS íŒŒë¼ë¯¸í„° ì¡°ì •
results = model('image.jpg', conf=0.25, iou=0.45)

# íŠ¹ì • í´ë˜ìŠ¤ë§Œ íƒì§€
results = model('image.jpg', classes=[0, 2, 3])  # person, car, motorcycle

# ì´ë¯¸ì§€ ì¦ê°• í…ŒìŠ¤íŠ¸ (TTA) - ë” ë†’ì€ ì •í™•ë„
results = model('image.jpg', augment=True)
```

### ë°°ì¹˜ ì²˜ë¦¬

```python
from ultralytics import YOLO
import glob

model = YOLO('yolov11n.pt')

# ì´ë¯¸ì§€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
images = glob.glob('path/to/images/*.jpg')

# ë°°ì¹˜ ì²˜ë¦¬ (ë” ë¹ ë¦„)
results = model(images, batch=8)

# ê²°ê³¼ ì €ì¥
for i, result in enumerate(results):
    result.save(f'output_{i}.jpg')
```

---

## ğŸ“¤ ëª¨ë¸ ë‚´ë³´ë‚´ê¸°

### ì§€ì› í˜•ì‹

| í˜•ì‹ | ëª…ë ¹ | ì¥ì  | ìš©ë„ |
|------|------|------|------|
| PyTorch | `format=torchscript` | ì›ë³¸ ì •í™•ë„ | Python ë°°í¬ |
| ONNX | `format=onnx` | ë²”ìš©ì„± | ë‹¤ì–‘í•œ í”„ë ˆì„ì›Œí¬ |
| TensorRT | `format=engine` | ìµœê³  ì†ë„ | NVIDIA GPU |
| CoreML | `format=coreml` | iOS ìµœì í™” | Apple ê¸°ê¸° |
| TFLite | `format=tflite` | ê²½ëŸ‰ | Android/ì„ë² ë””ë“œ |
| OpenVINO | `format=openvino` | Intel CPU ìµœì í™” | Intel í•˜ë“œì›¨ì–´ |

### ë‚´ë³´ë‚´ê¸° ì˜ˆì œ

```python
from ultralytics import YOLO

model = YOLO('yolov11n.pt')

# ONNXë¡œ ë‚´ë³´ë‚´ê¸°
model.export(format='onnx')

# TensorRTë¡œ ë‚´ë³´ë‚´ê¸° (ë™ì  ë°°ì¹˜)
model.export(format='engine', dynamic=True)

# CoreMLë¡œ ë‚´ë³´ë‚´ê¸° (iOS)
model.export(format='coreml')

# TensorFlow Liteë¡œ ë‚´ë³´ë‚´ê¸° (INT8 ì–‘ìí™”)
model.export(format='tflite', int8=True)

# OpenVINOë¡œ ë‚´ë³´ë‚´ê¸°
model.export(format='openvino')
```

### CLIë¡œ ë‚´ë³´ë‚´ê¸°

```bash
# ONNX
yolo export model=yolov11n.pt format=onnx

# TensorRT (FP16)
yolo export model=yolov11n.pt format=engine half=True

# CoreML
yolo export model=yolov11n.pt format=coreml

# INT8 ì–‘ìí™”ëœ TFLite
yolo export model=yolov11n.pt format=tflite int8=True
```

### ë‚´ë³´ë‚¸ ëª¨ë¸ ì‚¬ìš©

```python
from ultralytics import YOLO

# ONNX ëª¨ë¸ ë¡œë“œ ë° ì¶”ë¡ 
model = YOLO('yolov11n.onnx')
results = model('image.jpg')

# TensorRT ì—”ì§„ ì‚¬ìš©
model = YOLO('yolov11n.engine')
results = model('image.jpg')
```

---

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### COCO Dataset ì„±ëŠ¥

| ëª¨ë¸ | í¬ê¸°<br>(pixels) | mAP50-95 | mAP50 | íŒŒë¼ë¯¸í„°<br>(M) | FLOPs<br>(G) | ì†ë„<br>CPU (ms) | ì†ë„<br>T4 (ms) |
|------|-----------------|----------|-------|----------------|--------------|-----------------|----------------|
| YOLOv11n | 640 | 39.5 | 56.1 | 2.6 | 6.5 | 56.1 | 1.5 |
| YOLOv11s | 640 | 47.0 | 63.6 | 9.4 | 21.5 | 90.0 | 2.5 |
| YOLOv11m | 640 | 51.5 | 68.0 | 20.1 | 68.0 | 183.2 | 4.7 |
| YOLOv11l | 640 | 53.4 | 70.0 | 25.3 | 86.9 | 238.6 | 6.2 |
| YOLOv11x | 640 | 54.7 | 71.3 | 56.9 | 194.9 | 462.8 | 11.3 |

### ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„±ëŠ¥

| ëª¨ë¸ | í¬ê¸° | mAP50-95 (box) | mAP50-95 (mask) | ì†ë„ (ms) |
|------|------|----------------|-----------------|-----------|
| YOLOv11n-seg | 640 | 38.9 | 32.0 | 1.8 |
| YOLOv11s-seg | 640 | 46.6 | 37.8 | 2.9 |
| YOLOv11m-seg | 640 | 51.5 | 41.5 | 5.1 |
| YOLOv11l-seg | 640 | 53.4 | 42.9 | 6.9 |
| YOLOv11x-seg | 640 | 54.7 | 43.8 | 12.0 |

### í¬ì¦ˆ ì¶”ì • ì„±ëŠ¥

| ëª¨ë¸ | í¬ê¸° | mAP50-95 | mAP50 | ì†ë„ (ms) |
|------|------|----------|-------|-----------|
| YOLOv11n-pose | 640 | 50.0 | 81.0 | 1.7 |
| YOLOv11s-pose | 640 | 58.9 | 86.4 | 2.6 |
| YOLOv11m-pose | 640 | 64.9 | 89.4 | 4.9 |
| YOLOv11l-pose | 640 | 66.1 | 89.9 | 6.4 |
| YOLOv11x-pose | 640 | 69.5 | 91.1 | 11.0 |

---

## âš™ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°

### í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„°

```yaml
# ê¸°ë³¸ í•™ìŠµ ì„¤ì •
lr0: 0.01              # ì´ˆê¸° í•™ìŠµë¥ 
lrf: 0.01              # ìµœì¢… í•™ìŠµë¥  (lr0 * lrf)
momentum: 0.937        # SGD ëª¨ë©˜í…€/Adam beta1
weight_decay: 0.0005   # ê°€ì¤‘ì¹˜ ê°ì‡ 
warmup_epochs: 3.0     # ì›Œë°ì—… ì—í¬í¬
warmup_momentum: 0.8   # ì›Œë°ì—… ì´ˆê¸° ëª¨ë©˜í…€
warmup_bias_lr: 0.1    # ì›Œë°ì—… ì´ˆê¸° ë°”ì´ì–´ìŠ¤ lr
box: 7.5               # ë°•ìŠ¤ ì†ì‹¤ ê°€ì¤‘ì¹˜
cls: 0.5               # í´ë˜ìŠ¤ ì†ì‹¤ ê°€ì¤‘ì¹˜
dfl: 1.5               # DFL ì†ì‹¤ ê°€ì¤‘ì¹˜
pose: 12.0             # í¬ì¦ˆ ì†ì‹¤ ê°€ì¤‘ì¹˜ (pose-only)
kobj: 1.0              # í‚¤í¬ì¸íŠ¸ ê°ì²´ ì†ì‹¤ ê°€ì¤‘ì¹˜ (pose-only)
label_smoothing: 0.0   # ë¼ë²¨ ìŠ¤ë¬´ë”© (epsilon)
nbs: 64                # ëª…ëª© ë°°ì¹˜ í¬ê¸°
overlap_mask: True     # ë§ˆìŠ¤í¬ ì˜¤ë²„ë© í•™ìŠµ (segment)
mask_ratio: 4          # ë§ˆìŠ¤í¬ ë‹¤ìš´ìƒ˜í”Œ ë¹„ìœ¨ (segment)
dropout: 0.0           # ë¶„ë¥˜ Dropout (val/train 0.0)
val: True              # í•™ìŠµ ì¤‘ ê²€ì¦
```

### ì¦ê°• í•˜ì´í¼íŒŒë¼ë¯¸í„°

```yaml
hsv_h: 0.015          # ì´ë¯¸ì§€ HSV-Hue ì¦ê°• (fraction)
hsv_s: 0.7            # ì´ë¯¸ì§€ HSV-Saturation ì¦ê°• (fraction)
hsv_v: 0.4            # ì´ë¯¸ì§€ HSV-Value ì¦ê°• (fraction)
degrees: 0.0          # ì´ë¯¸ì§€ íšŒì „ (+/- deg)
translate: 0.1        # ì´ë¯¸ì§€ ì´ë™ (+/- fraction)
scale: 0.5            # ì´ë¯¸ì§€ ìŠ¤ì¼€ì¼ (+/- gain)
shear: 0.0            # ì´ë¯¸ì§€ ì „ë‹¨ (+/- deg)
perspective: 0.0      # ì´ë¯¸ì§€ ì›ê·¼ (+/- fraction), range 0-0.001
flipud: 0.0           # ì´ë¯¸ì§€ ìƒí•˜ ë’¤ì§‘ê¸° (probability)
fliplr: 0.5           # ì´ë¯¸ì§€ ì¢Œìš° ë’¤ì§‘ê¸° (probability)
bgr: 0.0              # BGR ì±„ë„ ë’¤ì§‘ê¸° (probability)
mosaic: 1.0           # ì´ë¯¸ì§€ ëª¨ìì´í¬ (probability)
mixup: 0.0            # ì´ë¯¸ì§€ ë¯¹ìŠ¤ì—… (probability)
copy_paste: 0.0       # ì„¸ê·¸ë¨¼íŠ¸ ë³µì‚¬-ë¶™ì—¬ë„£ê¸° (probability)
auto_augment: randaugment  # ìë™ ì¦ê°• ì •ì±… (randaugment, autoaugment, augmix)
erasing: 0.4          # ë¶„ë¥˜ í•™ìŠµ ì¤‘ ëœë¤ ì§€ìš°ê¸° (probability, ë¶„ë¥˜ ì „ìš©)
crop_fraction: 1.0    # ë¶„ë¥˜ ì´ë¯¸ì§€ ìë¥´ê¸° ë¹„ìœ¨ (fraction, ë¶„ë¥˜ ì „ìš©)
```

---

## ğŸ’¡ Tips & Tricks

### 1. ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ

**ì‘ì€ ê°ì²´ íƒì§€:**
- ë” í° ì´ë¯¸ì§€ í¬ê¸° ì‚¬ìš© (`imgsz=1280`)
- YOLOv11l ë˜ëŠ” YOLOv11x ì¶”ì²œ

**ì‹¤ì‹œê°„ ì¶”ë¡ :**
- YOLOv11n ë˜ëŠ” YOLOv11s ì‚¬ìš©
- ì‘ì€ ì´ë¯¸ì§€ í¬ê¸° (`imgsz=640` ë˜ëŠ” `imgsz=416`)
- TensorRTë¡œ ë‚´ë³´ë‚´ê¸°

**ë†’ì€ ì •í™•ë„:**
- YOLOv11x ì‚¬ìš©
- í° ì´ë¯¸ì§€ í¬ê¸° (`imgsz=1280`)
- TTA (Test Time Augmentation) í™œì„±í™”

**ì—£ì§€ ë””ë°”ì´ìŠ¤:**
- YOLOv11n ì‚¬ìš©
- INT8 ì–‘ìí™”
- TFLite ë˜ëŠ” CoreMLë¡œ ë‚´ë³´ë‚´ê¸°

### 2. í•™ìŠµ ê°œì„  íŒ

**ë°ì´í„°ì…‹:**
- í´ë˜ìŠ¤ë‹¹ ìµœì†Œ 1500ê°œ ì´ë¯¸ì§€ ê¶Œì¥
- ë‹¤ì–‘í•œ ì¡°ëª…, ê°ë„, ë°°ê²½ ì‚¬ìš©
- ë°ì´í„° ì¦ê°• í™œìš©

**í•˜ì´í¼íŒŒë¼ë¯¸í„°:**
- í•™ìŠµë¥ : ë°°ì¹˜ í¬ê¸°ì— ë¹„ë¡€í•˜ì—¬ ì¡°ì •
- Mosaic ì¦ê°•: ì‘ì€ ê°ì²´ íƒì§€ì— íš¨ê³¼ì 
- MixUp: ê³¼ì í•© ë°©ì§€

**ì „ì´ í•™ìŠµ:**
- í•­ìƒ ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¡œ ì‹œì‘
- ì ì€ ë°ì´í„°: ë” ì ì€ ì—í¬í¬, ë†’ì€ í•™ìŠµë¥ 
- ë§ì€ ë°ì´í„°: ë” ë§ì€ ì—í¬í¬, ë‚®ì€ í•™ìŠµë¥ 

### 3. ì¶”ë¡  ìµœì í™”

**ì†ë„ í–¥ìƒ:**
```python
# FP16 ì‚¬ìš©
results = model('image.jpg', half=True)

# ë°°ì¹˜ ì²˜ë¦¬
results = model(images, batch=8)

# ë” ì‘ì€ ì´ë¯¸ì§€ í¬ê¸°
results = model('image.jpg', imgsz=416)

# NMS ìµœì í™”
results = model('image.jpg', conf=0.5, iou=0.7, max_det=100)
```

**ì •í™•ë„ í–¥ìƒ:**
```python
# ë” í° ì´ë¯¸ì§€ í¬ê¸°
results = model('image.jpg', imgsz=1280)

# TTA ì‚¬ìš©
results = model('image.jpg', augment=True)

# ë” ë‚®ì€ ì‹ ë¢°ë„ ì„ê³„ê°’
results = model('image.jpg', conf=0.001)
```

### 4. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ íŒ

**ë¼ë²¨ë§:**
- [Roboflow](https://roboflow.com/) ì‚¬ìš©
- [Label Studio](https://labelstud.io/) ì‚¬ìš©
- [CVAT](https://www.cvat.ai/) ì‚¬ìš©

**ë°ì´í„° ë¶„í• :**
- Train: 70-80%
- Validation: 10-20%
- Test: 10-20%

**ë°ì´í„° í’ˆì§ˆ:**
- ëª…í™•í•œ ê°ì²´ ê²½ê³„
- ì¼ê´€ëœ ë¼ë²¨ë§ ê·œì¹™
- ì˜¤íƒ ìµœì†Œí™”

### 5. ë””ë²„ê¹…

```python
# í•™ìŠµ ì‹œê°í™”
from ultralytics import YOLO

model = YOLO('yolov11n.pt')
results = model.train(
    data='custom.yaml',
    epochs=100,
    plots=True,  # í•™ìŠµ í”Œë¡¯ ìƒì„±
    verbose=True  # ìƒì„¸ ë¡œê·¸
)

# TensorBoard
# tensorboard --logdir runs/train
```

**í•™ìŠµ ë¬¸ì œ í•´ê²°:**
- ì†ì‹¤ì´ ê°ì†Œí•˜ì§€ ì•ŠìŒ â†’ í•™ìŠµë¥  ë‚®ì¶”ê¸°
- ê³¼ì í•© â†’ ë°ì´í„° ì¦ê°•, Dropout ì¦ê°€
- ë‚®ì€ mAP â†’ ë” ê¸´ í•™ìŠµ, ë” í° ëª¨ë¸

---

## â“ FAQ

### Q1: YOLOv11ê³¼ YOLOv8ì˜ ì°¨ì´ì ì€?
**A:** YOLOv11ì€ ë” ì ì€ íŒŒë¼ë¯¸í„°ë¡œ ë” ë†’ì€ ì •í™•ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì•½ 22% ë¹ ë¥¸ ì¶”ë¡  ì†ë„ì™€ 2-3% ë†’ì€ mAPë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

### Q2: ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ë°©ë²•ì€?
**A:** ë°ì´í„°ë¥¼ YOLO í˜•ì‹ìœ¼ë¡œ ì¤€ë¹„í•˜ê³  YAML íŒŒì¼ì„ ë§Œë“  í›„, `model.train(data='custom.yaml')`ë¡œ í•™ìŠµí•˜ì„¸ìš”.

### Q3: ì–´ë–¤ ëª¨ë¸ì„ ì„ íƒí•´ì•¼ í•˜ë‚˜ìš”?
**A:** 
- ì‹¤ì‹œê°„/ëª¨ë°”ì¼: YOLOv11n ë˜ëŠ” YOLOv11s
- ì¼ë°˜ ìš©ë„: YOLOv11m
- ë†’ì€ ì •í™•ë„: YOLOv11l ë˜ëŠ” YOLOv11x

### Q4: GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.
**A:** ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì´ê±°ë‚˜ (`batch=8` â†’ `batch=4`) ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¤„ì´ì„¸ìš” (`imgsz=640` â†’ `imgsz=416`).

### Q5: í•™ìŠµ ì†ë„ë¥¼ ë†’ì´ëŠ” ë°©ë²•ì€?
**A:** 
- ë” ì‘ì€ ì´ë¯¸ì§€ í¬ê¸° ì‚¬ìš©
- ë°°ì¹˜ í¬ê¸° ì¦ê°€ (GPU ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•œ ê²½ìš°)
- Mixed Precision Training (`amp=True`)
- ë‹¤ì¤‘ GPU ì‚¬ìš©

### Q6: ì‘ì€ ê°ì²´ íƒì§€ë¥¼ ê°œì„ í•˜ë ¤ë©´?
**A:**
- ë” í° ì´ë¯¸ì§€ í¬ê¸° (`imgsz=1280`)
- Mosaic ì¦ê°• í™œì„±í™”
- ë” í° ëª¨ë¸ ì‚¬ìš© (YOLOv11l, YOLOv11x)

### Q7: ëª¨ë¸ì„ ëª¨ë°”ì¼ ê¸°ê¸°ì— ë°°í¬í•˜ë ¤ë©´?
**A:**
- iOS: CoreMLë¡œ ë‚´ë³´ë‚´ê¸° (`format=coreml`)
- Android: TFLiteë¡œ ë‚´ë³´ë‚´ê¸° (`format=tflite`)
- INT8 ì–‘ìí™”ë¡œ í¬ê¸° ê°ì†Œ

### Q8: ì¶”ë¡  ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥í•˜ë ¤ë©´?
**A:**
```python
results = model('image.jpg')
json_data = results[0].tojson()
import json
with open('results.json', 'w') as f:
    f.write(json_data)
```

### Q9: íŠ¹ì • í´ë˜ìŠ¤ë§Œ í•™ìŠµí•  ìˆ˜ ìˆë‚˜ìš”?
**A:** ë„¤, ë°ì´í„°ì…‹ YAML íŒŒì¼ì—ì„œ í•„ìš”í•œ í´ë˜ìŠ¤ë§Œ ì •ì˜í•˜ë©´ ë©ë‹ˆë‹¤.

### Q10: ì „ì´ í•™ìŠµ vs ì²˜ìŒë¶€í„° í•™ìŠµ?
**A:** ê±°ì˜ í•­ìƒ ì „ì´ í•™ìŠµì„ ê¶Œì¥í•©ë‹ˆë‹¤. ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ëŠ” ë” ë¹ ë¥¸ ìˆ˜ë ´ê³¼ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Ultralytics ê³µì‹ ë¬¸ì„œ](https://docs.ultralytics.com/)
- [YOLOv11 GitHub](https://github.com/ultralytics/ultralytics)
- [Ultralytics Hub](https://hub.ultralytics.com/)

### ë°ì´í„°ì…‹ í¬ê¸°ë³„ í•˜ì´í¼íŒŒë¼ë¯¸í„°

#### ì‘ì€ ë°ì´í„°ì…‹ (< 1000 ì´ë¯¸ì§€)

```yaml
# ê³¼ì í•© ë°©ì§€ì— ì¤‘ì 
lr0: 0.001              # ë‚®ì€ í•™ìŠµë¥ 
epochs: 200             # ë” ë§ì€ ì—í¬í¬
patience: 50            # ê¸´ patience
dropout: 0.1            # Dropout ì¶”ê°€
label_smoothing: 0.1    # ë¼ë²¨ ìŠ¤ë¬´ë”©
mosaic: 1.0
mixup: 0.2              # MixUp í™œì„±í™”
copy_paste: 0.1
# ê°•í•œ ì¦ê°•
degrees: 15.0
translate: 0.2
scale: 0.5
hsv_h: 0.02
hsv_s: 0.8
hsv_v: 0.5
```

#### ì¤‘ê°„ ë°ì´í„°ì…‹ (1000-10000 ì´ë¯¸ì§€)

```yaml
# ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
lr0: 0.01
epochs: 100
patience: 50
mosaic: 1.0
mixup: 0.0
# ì ë‹¹í•œ ì¦ê°•
degrees: 0.0
translate: 0.1
scale: 0.5
```

#### í° ë°ì´í„°ì…‹ (> 10000 ì´ë¯¸ì§€)

```yaml
# ë¹ ë¥¸ ìˆ˜ë ´ì— ì¤‘ì 
lr0: 0.01               # í‘œì¤€ í•™ìŠµë¥ 
epochs: 300             # ì¶©ë¶„í•œ í•™ìŠµ
patience: 100
mosaic: 1.0
mixup: 0.0
# ì•½í•œ ì¦ê°• (ë°ì´í„°ê°€ ì¶©ë¶„)
degrees: 0.0
translate: 0.1
scale: 0.5
close_mosaic: 10        # ë§ˆì§€ë§‰ 10 ì—í¬í¬ mosaic ë„ê¸°
```

### í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬

```yaml
# Linear warmup + Cosine annealing (ê¸°ë³¸)
warmup_epochs: 3.0
cos_lr: True            # Cosine LR scheduler

# Linear warmup + Linear decay
warmup_epochs: 3.0
cos_lr: False

# One-cycle policy
optimizer: 'Adam'
lr0: 0.001
lrf: 0.1
```

---

## ğŸ’¡ Tips & Tricks

### 1. ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ

#### ì‚¬ìš© ì¼€ì´ìŠ¤ë³„ ì¶”ì²œ

| ì‚¬ìš© ì¼€ì´ìŠ¤ | ì¶”ì²œ ëª¨ë¸ | ì´ë¯¸ì§€ í¬ê¸° | ì´ìœ  |
|------------|----------|-----------|------|
| **ë¼ì¦ˆë² ë¦¬íŒŒì´** | YOLOv11n | 320-416 | ìµœì†Œ íŒŒë¼ë¯¸í„°, CPU ìµœì í™” |
| **Jetson Nano** | YOLOv11n/s | 416-640 | ì œí•œëœ GPU ë©”ëª¨ë¦¬ |
| **Jetson Xavier** | YOLOv11s/m | 640 | ì ì ˆí•œ ì„±ëŠ¥/ì†ë„ ê· í˜• |
| **ëª¨ë°”ì¼ (iOS)** | YOLOv11s | 640 | CoreML ìµœì í™” |
| **ëª¨ë°”ì¼ (Android)** | YOLOv11s | 640 | TFLite INT8 |
| **ì‹¤ì‹œê°„ CCTV** | YOLOv11m | 640-1280 | ì •í™•ë„ì™€ ì†ë„ ê· í˜• |
| **ë“œë¡  ì˜ìƒ** | YOLOv11s/m | 640 | ê²½ëŸ‰, ë°°í„°ë¦¬ íš¨ìœ¨ |
| **ììœ¨ì£¼í–‰** | YOLOv11l/x | 1280 | ë†’ì€ ì •í™•ë„ í•„ìˆ˜ |
| **ì˜ë£Œ ì˜ìƒ** | YOLOv11x | 1280 | ìµœê³  ì •í™•ë„ |
| **ì†Œë§¤ ë¶„ì„** | YOLOv11m | 640 | ì‹¤ì‹œê°„ + ì •í™•ë„ |
| **ìŠ¤í¬ì¸  ë¶„ì„** | YOLOv11l | 1280 | ë¹ ë¥¸ ì›€ì§ì„ ì¶”ì  |
| **ì‚°ì—… ê²€ì‚¬** | YOLOv11l/x | 1280 | ì •ë°€ íƒì§€ í•„ìš” |
| **ì–¼êµ´ ì¸ì‹** | YOLOv11m | 640 | ì¤‘ê°„ í¬ê¸° ê°ì²´ |
| **ì°¨ëŸ‰ ë²ˆí˜¸íŒ** | YOLOv11l | 1280 | ì‘ì€ í…ìŠ¤íŠ¸ ì½ê¸° |

### 2. ì„±ëŠ¥ ê°œì„  ì „ëµ

#### ì •í™•ë„ í–¥ìƒ

**1. ë°ì´í„° í’ˆì§ˆ ê°œì„ **
```python
# ë°ì´í„° ê²€ì¦
from ultralytics import YOLO

model = YOLO('yolov11n.pt')

# ë°ì´í„°ì…‹ ë¶„ì„
model.val(data='custom.yaml', split='train')

# ì˜ëª»ëœ ë¼ë²¨ ì°¾ê¸°
# - mAPê°€ ë§¤ìš° ë‚®ì€ ì´ë¯¸ì§€
# - ë†’ì€ FP/FN ì´ë¯¸ì§€
```

**2. ë” í° ëª¨ë¸ ì‚¬ìš©**
```python
# n -> s -> m -> l -> x
model = YOLO('yolov11x.pt')  # ìµœê³  ì„±ëŠ¥
```

**3. ë” í° ì´ë¯¸ì§€ í¬ê¸°**
```python
model.train(
    data='custom.yaml',
    imgsz=1280,  # ê¸°ë³¸ 640ì—ì„œ ì¦ê°€
    epochs=100
)
```

**4. ë” ê¸´ í•™ìŠµ**
```python
model.train(
    data='custom.yaml',
    epochs=300,   # 100ì—ì„œ ì¦ê°€
    patience=100  # ì¡°ê¸° ì¢…ë£Œ ëŠ¦ì¶¤
)
```

**5. ë°ì´í„° ì¦ê°• ê°•í™”**
```python
model.train(
    data='custom.yaml',
    epochs=100,
    # ê°•í•œ ì¦ê°•
    mosaic=1.0,
    mixup=0.2,
    copy_paste=0.1,
    degrees=15.0,
    translate=0.2,
    scale=0.5,
    hsv_h=0.02,
    hsv_s=0.8,
    hsv_v=0.5
)
```

**6. ì•™ìƒë¸”**
```python
from ultralytics import YOLO
import numpy as np

# ì—¬ëŸ¬ ëª¨ë¸ ë¡œë“œ
models = [
    YOLO('yolov11m.pt'),
    YOLO('yolov11l.pt'),
    YOLO('yolov11x.pt')
]

# ê²°ê³¼ ìˆ˜ì§‘
all_results = []
for model in models:
    results = model('image.jpg')
    all_results.append(results[0].boxes)

# NMSë¡œ ë³‘í•© (ì§ì ‘ êµ¬í˜„ í•„ìš”)
# WBF (Weighted Boxes Fusion) ê¶Œì¥
```

#### ì†ë„ í–¥ìƒ

**1. ë” ì‘ì€ ëª¨ë¸**
```python
model = YOLO('yolov11n.pt')  # ê°€ì¥ ë¹ ë¦„
```

**2. ë” ì‘ì€ ì´ë¯¸ì§€**
```python
results = model('image.jpg', imgsz=416)  # 640 -> 416
```

**3. TensorRT ì‚¬ìš©**
```python
# ë‚´ë³´ë‚´ê¸°
model.export(format='engine', half=True)

# ì‚¬ìš© (5-10ë°° ë¹ ë¦„)
trt_model = YOLO('yolov11n.engine')
results = trt_model('image.jpg')
```

**4. ë°°ì¹˜ ì²˜ë¦¬**
```python
# ë‹¨ì¼ ì²˜ë¦¬
for img in images:
    results = model(img)  # ëŠë¦¼

# ë°°ì¹˜ ì²˜ë¦¬
results = model(images, batch=16)  # ë¹ ë¦„
```

**5. FP16 ì‚¬ìš©**
```python
results = model('image.jpg', half=True, device=0)
```

**6. NMS ìµœì í™”**
```python
results = model('image.jpg',
                conf=0.5,      # ë†’ì€ ì„ê³„ê°’
                iou=0.7,       # ë†’ì€ IoU
                max_det=100)   # ìµœëŒ€ íƒì§€ ì œí•œ
```

### 3. ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

#### ë¬¸ì œ: ë‚®ì€ mAP

**ì›ì¸ ë° í•´ê²°:**

1. **ë°ì´í„° ë¶€ì¡±**
   - í•´ê²°: í´ë˜ìŠ¤ë‹¹ ìµœì†Œ 1500ê°œ ì´ë¯¸ì§€
   - ë°ì´í„° ì¦ê°• ê°•í™”
   - ì˜¨ë¼ì¸ ë°ì´í„°ì…‹ ì¶”ê°€

2. **ì˜ëª»ëœ ë¼ë²¨**
   - í•´ê²°: ë¼ë²¨ ê²€ì¦
   - ê²½ê³„ ë°•ìŠ¤ ì •í™•ë„ í™•ì¸
   - ì¼ê´€ëœ ë¼ë²¨ë§ ê¸°ì¤€

3. **í´ë˜ìŠ¤ ë¶ˆê· í˜•**
   - í•´ê²°: í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì¡°ì •
   - ì˜¤ë²„ìƒ˜í”Œë§
   - Focal Loss ì‚¬ìš©

4. **ë„ˆë¬´ ì§§ì€ í•™ìŠµ**
   - í•´ê²°: ë” ë§ì€ ì—í¬í¬
   - patience ì¦ê°€

5. **ë¶€ì ì ˆí•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°**
   - í•´ê²°: í•™ìŠµë¥  ì¡°ì •
   - ì¦ê°• íŒŒë¼ë¯¸í„° íŠœë‹

#### ë¬¸ì œ: ê³¼ì í•©

**ì¦ìƒ:**
- Train mAP ë†’ìŒ, Val mAP ë‚®ìŒ
- Train loss ê³„ì† ê°ì†Œ, Val loss ì¦ê°€

**í•´ê²°:**

```python
model.train(
    data='custom.yaml',
    epochs=100,
    # ê³¼ì í•© ë°©ì§€
    dropout=0.1,
    label_smoothing=0.1,
    # ê°•í•œ ì¦ê°•
    mosaic=1.0,
    mixup=0.2,
    degrees=15.0,
    translate=0.2,
    # ì •ê·œí™”
    weight_decay=0.001,
    # ë” ì‘ì€ ëª¨ë¸
    model='yolov11s.pt'
)
```

#### ë¬¸ì œ: í•™ìŠµì´ ìˆ˜ë ´í•˜ì§€ ì•ŠìŒ

**ì¦ìƒ:**
- Lossê°€ ê°ì†Œí•˜ì§€ ì•ŠìŒ
- mAPê°€ ë§¤ìš° ë‚®ìŒ

**í•´ê²°:**

1. **í•™ìŠµë¥  ë‚®ì¶”ê¸°**
```python
model.train(
    data='custom.yaml',
    lr0=0.001,  # 0.01ì—ì„œ ê°ì†Œ
    lrf=0.001
)
```

2. **ì›Œë°ì—… ëŠ˜ë¦¬ê¸°**
```python
model.train(
    data='custom.yaml',
    warmup_epochs=5.0  # 3.0ì—ì„œ ì¦ê°€
)
```

3. **ë°°ì¹˜ í¬ê¸° ì¦ê°€**
```python
model.train(
    data='custom.yaml',
    batch=32  # 16ì—ì„œ ì¦ê°€
)
```

4. **ë°ì´í„° í™•ì¸**
- ë¼ë²¨ í˜•ì‹ ê²€ì¦
- ê²½ë¡œ í™•ì¸
- ì´ë¯¸ì§€ ë¡œë“œ í…ŒìŠ¤íŠ¸

#### ë¬¸ì œ: GPU ë©”ëª¨ë¦¬ ë¶€ì¡±

**í•´ê²°:**

```python
# 1. ë°°ì¹˜ í¬ê¸° ê°ì†Œ
model.train(batch=8)  # 16 -> 8

# 2. ì´ë¯¸ì§€ í¬ê¸° ê°ì†Œ
model.train(imgsz=416)  # 640 -> 416

# 3. ë” ì‘ì€ ëª¨ë¸
model = YOLO('yolov11n.pt')

# 4. ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  (êµ¬í˜„ í•„ìš”)
# 5. í˜¼í•© ì •ë°€ë„
model.train(amp=True)

# 6. ì›Œì»¤ ìˆ˜ ê°ì†Œ
model.train(workers=4)

# 7. ìºì‹œ ë¹„ìš°ê¸°
import torch
torch.cuda.empty_cache()
```

#### ë¬¸ì œ: ì‘ì€ ê°ì²´ íƒì§€ ì‹¤íŒ¨

**í•´ê²°:**

```python
model.train(
    data='custom.yaml',
    imgsz=1280,        # ë” í° ì´ë¯¸ì§€
    mosaic=1.0,        # Mosaic í™œì„±í™”
    copy_paste=0.1,    # Copy-paste
    model='yolov11l.pt'  # ë” í° ëª¨ë¸
)

# ì¶”ë¡  ì‹œ
results = model('image.jpg',
                imgsz=1280,
                conf=0.3,      # ë‚®ì€ ì„ê³„ê°’
                augment=True)  # TTA
```

### 4. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ì¤€ë¹„ ì²´í¬ë¦¬ìŠ¤íŠ¸

**âœ… ë°ì´í„° ìˆ˜ì§‘**
- [ ] í´ë˜ìŠ¤ë‹¹ ìµœì†Œ 1500ê°œ ì´ë¯¸ì§€ (ì´ìƒì ìœ¼ë¡œ 5000+)
- [ ] ë‹¤ì–‘í•œ ì¡°ëª… ì¡°ê±´
- [ ] ë‹¤ì–‘í•œ ê°ë„ì™€ ê±°ë¦¬
- [ ] ë‹¤ì–‘í•œ ë°°ê²½
- [ ] ì‹¤ì œ ì‚¬ìš© í™˜ê²½ê³¼ ìœ ì‚¬

**âœ… ë¼ë²¨ë§**
- [ ] ì¼ê´€ëœ ë¼ë²¨ë§ ê¸°ì¤€
- [ ] ì •í™•í•œ ê²½ê³„ ë°•ìŠ¤
- [ ] ê²¹ì¹˜ëŠ” ê°ì²´ ì²˜ë¦¬
- [ ] ë¶€ë¶„ì ìœ¼ë¡œ ê°€ë ¤ì§„ ê°ì²´ í¬í•¨
- [ ] ì–´ë ¤ìš´ ì¼€ì´ìŠ¤ í¬í•¨

**âœ… ë°ì´í„° ë¶„í• **
- [ ] Train: 70-80%
- [ ] Validation: 10-20%
- [ ] Test: 10-20%
- [ ] ë¶„í•  í›„ í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸

**âœ… í˜•ì‹ í™•ì¸**
- [ ] YOLO í˜•ì‹ (class x y w h)
- [ ] ì •ê·œí™”ëœ ì¢Œí‘œ (0-1)
- [ ] íŒŒì¼ëª… ì¼ì¹˜ (image.jpg <-> image.txt)
- [ ] YAML íŒŒì¼ ì‘ì„±

**âœ… ê²€ì¦**
- [ ] ìƒ˜í”Œ ì´ë¯¸ì§€ ì‹œê°í™”
- [ ] ë¼ë²¨ ì •í™•ë„ í™•ì¸
- [ ] í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„
- [ ] ì´ìƒì¹˜ ì œê±°

### 5. í”„ë¡œë•ì…˜ ë°°í¬ ê°€ì´ë“œ

#### í´ë¼ìš°ë“œ ë°°í¬ (AWS/GCP/Azure)

**1. Docker ì»¨í…Œì´ë„ˆ**

```dockerfile
# Dockerfile
FROM ultralytics/ultralytics:latest

COPY yolov11n.pt /app/model.pt
COPY app.py /app/app.py

WORKDIR /app

CMD ["python", "app.py"]
```

```python
# app.py - Flask API
from flask import Flask, request, jsonify
from ultralytics import YOLO
import cv2
import numpy as np

app = Flask(__name__)
model = YOLO('model.pt')

@app.route('/predict', methods=['POST'])
def predict():
    file = request.files['image']
    img = cv2.imdecode(np.frombuffer(file.read(), np.uint8), cv2.IMREAD_COLOR)
    
    results = model(img)
    
    # ê²°ê³¼ ë³€í™˜
    detections = []
    for box in results[0].boxes:
        detections.append({
            'class': model.names[int(box.cls[0])],
            'confidence': float(box.conf[0]),
            'bbox': box.xyxy[0].tolist()
        })
    
    return jsonify(detections)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

**2. FastAPI ì„œë²„**

```python
# main.py
from fastapi import FastAPI, File, UploadFile
from ultralytics import YOLO
import cv2
import numpy as np

app = FastAPI()
model = YOLO('yolov11n.pt')

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    contents = await file.read()
    img = cv2.imdecode(np.frombuffer(contents, np.uint8), cv2.IMREAD_COLOR)
    
    results = model(img)
    
    detections = []
    for box in results[0].boxes:
        detections.append({
            'class': model.names[int(box.cls[0])],
            'confidence': float(box.conf[0]),
            'bbox': box.xyxy[0].tolist()
        })
    
    return {"detections": detections}

# ì‹¤í–‰: uvicorn main:app --host 0.0.0.0 --port 8000
```

#### ì—£ì§€ ë””ë°”ì´ìŠ¤ ë°°í¬

**1. Raspberry Pi**

```python
# rpi_inference.py
from ultralytics import YOLO
import cv2

# TFLite ëª¨ë¸ ì‚¬ìš© (CPU ìµœì í™”)
model = YOLO('yolov11n.tflite')

cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # ì¶”ë¡ 
    results = model(frame, imgsz=320)  # ì‘ì€ í¬ê¸°
    
    # í‘œì‹œ
    annotated = results[0].plot()
    cv2.imshow('YOLOv11', annotated)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

**2. NVIDIA Jetson**

```python
# jetson_inference.py
from ultralytics import YOLO

# TensorRT ì—”ì§„ ì‚¬ìš© (GPU ê°€ì†)
model = YOLO('yolov11n.engine')

# ì‹¤ì‹œê°„ ì²˜ë¦¬
results = model(0, stream=True)  # ì›¹ìº 

for result in results:
    result.show()
```

#### ëª¨ë°”ì¼ ë°°í¬

**iOS (Swift):**

```swift
import CoreML
import Vision

class YOLOv11Detector {
    let model: VNCoreMLModel
    
    init() {
        let mlModel = try! yolov11n()
        self.model = try! VNCoreMLModel(for: mlModel.model)
    }
    
    func detect(image: CGImage, completion: @escaping ([VNRecognizedObjectObservation]) -> Void) {
        let request = VNCoreMLRequest(model: model) { request, error in
            guard let results = request.results as? [VNRecognizedObjectObservation] else {
                completion([])
                return
            }
            completion(results)
        }
        
        request.imageCropAndScaleOption = .scaleFill
        
        let handler = VNImageRequestHandler(cgImage: image, options: [:])
        try? handler.perform([request])
    }
}
```

**Android (Kotlin):**

```kotlin
import org.tensorflow.lite.Interpreter
import java.nio.ByteBuffer

class YOLOv11Detector(modelPath: String) {
    private val interpreter: Interpreter
    
    init {
        interpreter = Interpreter(File(modelPath))
    }
    
    fun detect(bitmap: Bitmap): List<Detection> {
        // ì „ì²˜ë¦¬
        val input = preprocessImage(bitmap)
        
        // ì¶”ë¡ 
        val output = Array(1) { Array(8400) { FloatArray(84) } }
        interpreter.run(input, output)
        
        // í›„ì²˜ë¦¬
        return postprocess(output[0])
    }
    
    private fun preprocessImage(bitmap: Bitmap): ByteBuffer {
        // 640x640ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ ë° ì •ê·œí™”
        // ...
    }
    
    private fun postprocess(output: Array<FloatArray>): List<Detection> {
        // NMS ì ìš© ë° Detection ê°ì²´ ìƒì„±
        // ...
    }
}
```

### 6. ì‹¤ì „ ì˜ˆì œ

#### ì˜ˆì œ 1: ì‹¤ì‹œê°„ êµí†µ ë¶„ì„

```python
from ultralytics import YOLO
import cv2
from collections import defaultdict

model = YOLO('yolov11m.pt')

# ê´€ì‹¬ ì˜ì—­ (ROI) ì •ì˜
roi_line = [(300, 400), (900, 400)]

# ì¹´ìš´í„°
vehicle_count = defaultdict(int)
tracked_ids = set()

# ë¹„ë””ì˜¤ ì²˜ë¦¬
cap = cv2.VideoCapture('traffic.mp4')

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    # ì¶”ì  ëª¨ë“œ (ê°ì²´ ID ìœ ì§€)
    results = model.track(frame, persist=True, classes=[2, 3, 5, 7])  # car, motorcycle, bus, truck
    
    if results[0].boxes.id is not None:
        boxes = results[0].boxes.xyxy.cpu()
        track_ids = results[0].boxes.id.int().cpu().tolist()
        classes = results[0].boxes.cls.int().cpu().tolist()
        
        for box, track_id, cls in zip(boxes, track_ids, classes):
            x1, y1, x2, y2 = box
            center_y = (y1 + y2) / 2
            
            # ROI ë¼ì¸ì„ ë„˜ì—ˆëŠ”ì§€ í™•ì¸
            if track_id not in tracked_ids and center_y > roi_line[0][1]:
                vehicle_count[model.names[cls]] += 1
                tracked_ids.add(track_id)
    
    # ROI ë¼ì¸ ê·¸ë¦¬ê¸°
    cv2.line(frame, roi_line[0], roi_line[1], (0, 255, 0), 2)
    
    # ì¹´ìš´íŠ¸ í‘œì‹œ
    y_offset = 30
    for vehicle_type, count in vehicle_count.items():
        cv2.putText(frame, f"{vehicle_type}: {count}", (10, y_offset),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        y_offset += 40
    
    cv2.imshow('Traffic Analysis', frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

#### ì˜ˆì œ 2: PPE (ê°œì¸ ë³´í˜¸ ì¥ë¹„) ê°ì§€

```python
from ultralytics import YOLO
import cv2

# ì»¤ìŠ¤í…€ PPE ëª¨ë¸
model = YOLO('ppe_yolov11m.pt')  # í—¬ë©§, ì¡°ë¼, ì•ˆì „í™” ë“±

# í´ë˜ìŠ¤ ì •ì˜
REQUIRED_PPE = ['helmet', 'vest', 'safety_shoes']
ALERT_THRESHOLD = 0.5

def check_ppe_compliance(results, frame):
    """PPE ì°©ìš© ì—¬ë¶€ í™•ì¸"""
    detected_ppe = set()
    non_compliant = False
    
    for box in results[0].boxes:
        cls = int(box.cls[0])
        class_name = model.names[cls]
        conf = float(box.conf[0])
        
        if conf > ALERT_THRESHOLD:
            detected_ppe.add(class_name)
            
            # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            color = (0, 255, 0) if class_name in REQUIRED_PPE else (0, 0, 255)
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            cv2.putText(frame, f"{class_name} {conf:.2f}", (x1, y1-10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
    
    # ë¯¸ì°©ìš© í•­ëª© í™•ì¸
    missing_ppe = set(REQUIRED_PPE) - detected_ppe
    if missing_ppe:
        non_compliant = True
        warning = f"WARNING: Missing {', '.join(missing_ppe)}"
        cv2.putText(frame, warning, (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
    
    return frame, non_compliant

# ë¹„ë””ì˜¤ ì²˜ë¦¬
cap = cv2.VideoCapture('construction_site.mp4')

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    results = model(frame)
    annotated_frame, alert = check_ppe_compliance(results, frame)
    
    if alert:
        # ì•Œë¦¼ ì „ì†¡ (ì´ë©”ì¼, SMS ë“±)
        pass
    
    cv2.imshow('PPE Detection', annotated_frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

#### ì˜ˆì œ 3: ì–¼êµ´ ê°ì§€ ë° ë¸”ëŸ¬ ì²˜ë¦¬ (í”„ë¼ì´ë²„ì‹œ)

```python
from ultralytics import YOLO
import cv2

model = YOLO('yolov11n.pt')

def blur_faces(frame, results):
    """ì–¼êµ´ ì˜ì—­ ë¸”ëŸ¬ ì²˜ë¦¬"""
    for box in results[0].boxes:
        cls = int(box.cls[0])
        
        # ì‚¬ëŒ(class 0)ë§Œ ì²˜ë¦¬
        if cls == 0:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            
            # ì–¼êµ´ ì˜ì—­ ì¶”ì • (ìƒì²´ ìƒë‹¨ 1/3)
            face_h = (y2 - y1) // 3
            face_region = frame[y1:y1+face_h, x1:x2]
            
            # ë¸”ëŸ¬ ì ìš©
            if face_region.size > 0:
                blurred = cv2.GaussianBlur(face_region, (99, 99), 30)
                frame[y1:y1+face_h, x1:x2] = blurred
    
    return frame

# ë¹„ë””ì˜¤ ì²˜ë¦¬
cap = cv2.VideoCapture('input.mp4')
out = cv2.VideoWriter('output_blurred.mp4', 
                      cv2.VideoWriter_fourcc(*'mp4v'),
                      30, 
                      (int(cap.get(3)), int(cap.get(4))))

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    results = model(frame, classes=[0])  # personë§Œ
    blurred_frame = blur_faces(frame, results)
    
    out.write(blurred_frame)
    cv2.imshow('Privacy Protection', blurred_frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
out.release()
cv2.destroyAllWindows()
```

---

## â“ FAQ

### Q1: YOLOv11ê³¼ YOLOv8ì˜ ì°¨ì´ì ì€?
**A:** YOLOv11ì€ YOLOv8 ëŒ€ë¹„:
- íŒŒë¼ë¯¸í„° 19-22% ê°ì†Œ
- mAP 2-3% í–¥ìƒ
- ì¶”ë¡  ì†ë„ ì•½ 22% ê°œì„ 
- ìƒˆë¡œìš´ C3k2, C2PSA ëª¨ë“ˆ ë„ì…
- APIëŠ” ë™ì¼í•˜ì—¬ ì‰¬ìš´ ë§ˆì´ê·¸ë ˆì´ì…˜

### Q2: ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ë°©ë²•ì€?
**A:** 
1. YOLO í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ì¤€ë¹„ (images/, labels/)
2. YAML íŒŒì¼ ì‘ì„± (ê²½ë¡œ, í´ë˜ìŠ¤ ì •ì˜)
3. `model.train(data='custom.yaml')` ì‹¤í–‰
4. ìµœì†Œ í´ë˜ìŠ¤ë‹¹ 1500ê°œ ì´ë¯¸ì§€ ê¶Œì¥

### Q3: ì–´ë–¤ ëª¨ë¸ í¬ê¸°ë¥¼ ì„ íƒí•´ì•¼ í•˜ë‚˜ìš”?
**A:**
- **ì‹¤ì‹œê°„/ëª¨ë°”ì¼**: YOLOv11n ë˜ëŠ” YOLOv11s
- **ì¼ë°˜ ìš©ë„**: YOLOv11m
- **ë†’ì€ ì •í™•ë„**: YOLOv11l ë˜ëŠ” YOLOv11x
- **ì—£ì§€ ë””ë°”ì´ìŠ¤**: YOLOv11n + INT8 ì–‘ìí™”

### Q4: GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.
**A:** 
```python
# í•´ê²° ë°©ë²•:
model.train(
    batch=8,    # ë°°ì¹˜ í¬ê¸° ê°ì†Œ (16 -> 8)
    imgsz=416,  # ì´ë¯¸ì§€ í¬ê¸° ê°ì†Œ (640 -> 416)
    workers=4,  # ì›Œì»¤ ìˆ˜ ê°ì†Œ
    amp=True    # Mixed Precision
)
```

### Q5: í•™ìŠµ ì†ë„ë¥¼ ë†’ì´ëŠ” ë°©ë²•ì€?
**A:**
- ë‹¤ì¤‘ GPU ì‚¬ìš©: `device=[0,1,2,3]`
- Mixed Precision: `amp=True`
- ë” í° ë°°ì¹˜: `batch=32` (GPU í—ˆìš© ì‹œ)
- ë” ë§ì€ ì›Œì»¤: `workers=16`
- ë” ì‘ì€ ì´ë¯¸ì§€: `imgsz=416`

### Q6: ì‘ì€ ê°ì²´ íƒì§€ë¥¼ ê°œì„ í•˜ë ¤ë©´?
**A:**
```python
model.train(
    imgsz=1280,        # ë” í° ì´ë¯¸ì§€
    mosaic=1.0,        # Mosaic ì¦ê°•
    copy_paste=0.1,    # Copy-paste
    model='yolov11l.pt'  # ë” í° ëª¨ë¸
)

# ì¶”ë¡  ì‹œ
results = model('image.jpg', imgsz=1280, conf=0.3)
```

### Q7: ëª¨ë¸ì„ ëª¨ë°”ì¼ ê¸°ê¸°ì— ë°°í¬í•˜ë ¤ë©´?
**A:**
```python
# iOS
model.export(format='coreml', int8=True)

# Android
model.export(format='tflite', int8=True)

# í¬ê¸°: PyTorch (10MB) -> TFLite INT8 (2.5MB)
```

### Q8: ì¶”ë¡  ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥í•˜ë ¤ë©´?
**A:**
```python
results = model('image.jpg')
json_data = results[0].tojson()

import json
with open('results.json', 'w') as f:
    json.dump(json.loads(json_data), f, indent=2)
```

### Q9: íŠ¹ì • í´ë˜ìŠ¤ë§Œ í•™ìŠµí•  ìˆ˜ ìˆë‚˜ìš”?
**A:** ë„¤, YAML íŒŒì¼ì—ì„œ ì›í•˜ëŠ” í´ë˜ìŠ¤ë§Œ ì •ì˜í•˜ë©´ ë©ë‹ˆë‹¤:
```yaml
names:
  0: person
  1: car
nc: 2
```

### Q10: ì „ì´ í•™ìŠµ vs ì²˜ìŒë¶€í„° í•™ìŠµ?
**A:** **í•­ìƒ ì „ì´ í•™ìŠµ ê¶Œì¥!**
```python
# ì „ì´ í•™ìŠµ (ê¶Œì¥)
model = YOLO('yolov11n.pt')
model.train(data='custom.yaml')

# ì²˜ìŒë¶€í„° (ë¹„ê¶Œì¥)
model = YOLO('yolov11n.yaml')  # êµ¬ì¡°ë§Œ
model.train(data='custom.yaml', epochs=500)
```

### Q11: í•™ìŠµ ì¤‘ ê³¼ì í•©ì„ ë°©ì§€í•˜ë ¤ë©´?
**A:**
```python
model.train(
    data='custom.yaml',
    dropout=0.1,
    label_smoothing=0.1,
    mosaic=1.0,
    mixup=0.2,
    weight_decay=0.001,
    patience=30
)
```

### Q12: ì—¬ëŸ¬ GPUë¡œ í•™ìŠµí•˜ëŠ” ë°©ë²•ì€?
**A:**
```bash
# DDP (ê¶Œì¥)
yolo detect train data=custom.yaml model=yolov11n.pt device=0,1,2,3

# ë˜ëŠ” Python
model.train(data='custom.yaml', device=[0,1,2,3])
```

### Q13: í•™ìŠµì„ ì¬ê°œí•˜ë ¤ë©´?
**A:**
```python
# ìë™ ì¬ê°œ
model = YOLO('runs/detect/train/weights/last.pt')
model.train(resume=True)
```

### Q14: íƒì§€ ì‹ ë¢°ë„ë¥¼ ë†’ì´ë ¤ë©´?
**A:**
```python
# ì‹ ë¢°ë„ ì„ê³„ê°’ ì¡°ì •
results = model('image.jpg', conf=0.7)  # ê¸°ë³¸ 0.25

# NMS IoU ì¡°ì •
results = model('image.jpg', conf=0.5, iou=0.7)
```

### Q15: YOLOv11ë¡œ ì˜ìƒ ì¶”ì ì´ ê°€ëŠ¥í•œê°€ìš”?
**A:** ë„¤!
```python
# ê°ì²´ ì¶”ì  (BoT-SORT, ByteTrack)
results = model.track('video.mp4', persist=True)

for result in results:
    if result.boxes.id is not None:
        track_ids = result.boxes.id.int().cpu().tolist()
        # IDë³„ ì¶”ì  ì²˜ë¦¬
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Ultralytics ê³µì‹ ë¬¸ì„œ](https://docs.ultralytics.com/)
- [YOLOv11 GitHub](https://github.com/ultralytics/ultralytics)
- [Ultralytics Hub](https://hub.ultralytics.com/)
- [API Reference](https://docs.ultralytics.com/reference/)

### ë°ì´í„°ì…‹
- [COCO Dataset](https://cocodataset.org/)
- [Open Images](https://storage.googleapis.com/openimages/web/index.html)
- [Roboflow Universe](https://universe.roboflow.com/)
- [ImageNet](https://www.image-net.org/)
- [Pascal VOC](http://host.robots.ox.ac.uk/pascal/VOC/)

### íŠœí† ë¦¬ì–¼ ë° ê°€ì´ë“œ
- [YOLOv11 Quick Start](https://docs.ultralytics.com/quickstart/)
- [Custom Training Guide](https://docs.ultralytics.com/modes/train/)
- [Model Export Guide](https://docs.ultralytics.com/modes/export/)
- [Prediction Guide](https://docs.ultralytics.com/modes/predict/)
- [Validation Guide](https://docs.ultralytics.com/modes/val/)

### ë¼ë²¨ë§ ë„êµ¬
- [Roboflow](https://roboflow.com/) - ì›¹ ê¸°ë°˜, ìë™ ë³€í™˜
- [Label Studio](https://labelstud.io/) - ì˜¤í”ˆì†ŒìŠ¤
- [CVAT](https://www.cvat.ai/) - ë¹„ë””ì˜¤ ì§€ì›
- [LabelImg](https://github.com/HumanSignal/labelImg) - ê°„ë‹¨í•œ ë°ìŠ¤í¬í†±
- [Makesense.ai](https://www.makesense.ai/) - ì˜¨ë¼ì¸ ë¬´ë£Œ

### ì»¤ë®¤ë‹ˆí‹°
- [Ultralytics Discord](https://discord.gg/ultralytics)
- [GitHub Discussions](https://github.com/ultralytics/ultralytics/discussions)
- [Stack Overflow - YOLO](https://stackoverflow.com/questions/tagged/yolo)
- [Reddit r/computervision](https://www.reddit.com/r/computervision/)

### ë…¼ë¬¸ ë° ì—°êµ¬
- [YOLOv11 Technical Report](https://docs.ultralytics.com/) (ì¶œì‹œ ì˜ˆì •)
- [YOLOv8 Paper](https://arxiv.org/abs/...)
- [YOLOv7](https://arxiv.org/abs/2207.02696)
- [YOLO Series Overview](https://arxiv.org/search/?query=YOLO&searchtype=all)

### ë¸”ë¡œê·¸ ë° ê¸°ì‚¬
- [Ultralytics Blog](https://www.ultralytics.com/blog)
- [Roboflow Blog - YOLO](https://blog.roboflow.com/tag/yolo/)
- [Towards Data Science - YOLO](https://towardsdatascience.com/tagged/yolo)

### ë¹„ë””ì˜¤ íŠœí† ë¦¬ì–¼
- [Ultralytics YouTube](https://www.youtube.com/ultralytics)
- [YOLOv11 Tutorial Playlist](https://www.youtube.com/playlist?list=...)

### ë„êµ¬ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬
- [PyTorch](https://pytorch.org/)
- [OpenCV](https://opencv.org/)
- [TensorRT](https://developer.nvidia.com/tensorrt)
- [ONNX](https://onnx.ai/)
- [CoreML Tools](https://github.com/apple/coremltools)

---

## ğŸ“ ë¼ì´ì„ ìŠ¤

YOLOv11ì€ ë‘ ê°€ì§€ ë¼ì´ì„ ìŠ¤ë¡œ ì œê³µë©ë‹ˆë‹¤:

### AGPL-3.0 License
- **ì˜¤í”ˆì†ŒìŠ¤ ì‚¬ìš©**: ë¬´ë£Œ
- **ì¡°ê±´**: ì†ŒìŠ¤ ì½”ë“œ ê³µê°œ í•„ìš”
- **ìš©ë„**: ì—°êµ¬, êµìœ¡, ê°œì¸ í”„ë¡œì íŠ¸

### Enterprise License
- **ìƒì—…ì  ì‚¬ìš©**: ìœ ë£Œ
- **ì¡°ê±´**: ì†ŒìŠ¤ ì½”ë“œ ë¹„ê³µê°œ ê°€ëŠ¥
- **ìš©ë„**: ìƒì—… ì œí’ˆ, SaaS, í´ë¡œì¦ˆë“œ ì†ŒìŠ¤

ìì„¸í•œ ë‚´ìš©ì€ [Ultralytics ë¼ì´ì„ ìŠ¤ í˜ì´ì§€](https://ultralytics.com/license)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

---

## ğŸ¤ ê¸°ì—¬

ê¸°ì—¬ëŠ” ì–¸ì œë‚˜ í™˜ì˜í•©ë‹ˆë‹¤!

### ê¸°ì—¬ ë°©ë²•
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing`)
5. Open a Pull Request

### ì½”ë“œ ìŠ¤íƒ€ì¼
- PEP 8 ì¤€ìˆ˜
- íƒ€ì… íŒíŠ¸ ì‚¬ìš©
- Docstring ì‘ì„±
- í…ŒìŠ¤íŠ¸ ì½”ë“œ í¬í•¨

### ì´ìŠˆ ë¦¬í¬íŒ…
- [GitHub Issues](https://github.com/ultralytics/ultralytics/issues)
- ëª…í™•í•œ ì œëª©ê³¼ ì„¤ëª…
- ì¬í˜„ ê°€ëŠ¥í•œ ì˜ˆì œ
- í™˜ê²½ ì •ë³´ (OS, Python, PyTorch ë²„ì „)

---

## ğŸ™ ê°ì‚¬ì˜ ë§

ì´ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒ ë¶„ë“¤ì˜ ê¸°ì—¬ë¡œ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤:
- Ultralytics íŒ€
- YOLO ì»¤ë®¤ë‹ˆí‹°
- ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬ìë“¤

---

## ğŸ“§ ë¬¸ì˜

- **Email**: hello@ultralytics.com
- **GitHub**: [ultralytics/ultralytics](https://github.com/ultralytics/ultralytics)
- **Discord**: [Ultralytics ì»¤ë®¤ë‹ˆí‹°](https://discord.gg/ultralytics)
- **Twitter**: [@ultralytics](https://twitter.com/ultralytics)
- **LinkedIn**: [Ultralytics](https://www.linkedin.com/company/ultralytics/)

---

## ğŸ“ˆ ì—…ë°ì´íŠ¸ ë¡œê·¸

### v1.0.0 (2024-11)
- YOLOv11 ì™„ì „ ê°€ì´ë“œ ì´ˆíŒ ì‘ì„±
- YOLOv8 ë¹„êµ ì¶”ê°€
- ìš©ì–´ ì •ë¦¬ ì¶”ê°€
- ì‹¤ì „ ì˜ˆì œ ì¶”ê°€

---

<div align="center">

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2024ë…„ 11ì›”

**ì œì‘**: Ultralytics

**ë²„ì „**: YOLOv11 (2024)

---

Made with â¤ï¸ by the Ultralytics Team

[â¬† ë§¨ ìœ„ë¡œ](#yolov11-ì™„ì „-ê°€ì´ë“œ-complete-guide)

</div>ì…‹
- [COCO Dataset](https://cocodataset.org/)
- [Open Images](https://storage.googleapis.com/openimages/web/index.html)
- [Roboflow Universe](https://universe.roboflow.com/)

### íŠœí† ë¦¬ì–¼
- [YOLOv11 Quick Start](https://docs.ultralytics.com/quickstart/)
- [Custom Training Guide](https://docs.ultralytics.com/modes/train/)
- [Model Export Guide](https://docs.ultralytics.com/modes/export/)

### ì»¤ë®¤ë‹ˆí‹°
- [Ultralytics Discord](https://discord.gg/ultralytics)
- [GitHub Discussions](https://github.com/ultralytics/ultralytics/discussions)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/yolo)

### ë…¼ë¬¸
- [YOLOv11 Technical Report](https://arxiv.org/abs/...)
- [YOLOv8 Paper](https://arxiv.org/abs/...)

---

## ğŸ“ ë¼ì´ì„ ìŠ¤

YOLOv11ì€ ë‘ ê°€ì§€ ë¼ì´ì„ ìŠ¤ë¡œ ì œê³µë©ë‹ˆë‹¤:

- **AGPL-3.0 License**: ì˜¤í”ˆì†ŒìŠ¤ ì‚¬ìš©
- **Enterprise License**: ìƒì—…ì  ì‚¬ìš©

ìì„¸í•œ ë‚´ìš©ì€ [Ultralytics ë¼ì´ì„ ìŠ¤ í˜ì´ì§€](https://ultralytics.com/license)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

---

## ğŸ¤ ê¸°ì—¬

ê¸°ì—¬ëŠ” ì–¸ì œë‚˜ í™˜ì˜í•©ë‹ˆë‹¤! ì´ìŠˆë‚˜ í’€ ë¦¬í€˜ìŠ¤íŠ¸ë¥¼ ììœ ë¡­ê²Œ ì œì¶œí•´ì£¼ì„¸ìš”.

---

## ğŸ“§ ë¬¸ì˜

- **Email**: hello@ultralytics.com
- **GitHub Issues**: [ultralytics/ultralytics](https://github.com/ultralytics/ultralytics/issues)
- **Discord**: [Ultralytics ì»¤ë®¤ë‹ˆí‹°](https://discord.gg/ultralytics)

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2024ë…„ 11ì›”

**ì œì‘**: Ultralytics

**ë²„ì „**: YOLOv11 (2024)
